{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://arxiv.org/pdf/1810.04805.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T01:57:20.298165Z",
     "start_time": "2018-11-13T01:57:20.295510Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T01:57:20.717216Z",
     "start_time": "2018-11-13T01:57:20.300367Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T01:57:21.023628Z",
     "start_time": "2018-11-13T01:57:20.719286Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import collections\n",
    "import logging\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import six\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "\n",
    "import tokenization\n",
    "from modeling import BertConfig, BertForMaskedLanguageModelling\n",
    "from optimization import BERTAdam\n",
    "from masked_language_model import notqdm, convert_tokens_to_features, LMProcessor, predict_masked_words, predict_next_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T01:57:21.047342Z",
     "start_time": "2018-11-13T01:57:21.026094Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s', \n",
    "                    datefmt = '%m/%d/%Y %H:%M:%S',\n",
    "                    level = logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T10:41:27.497266Z",
     "start_time": "2018-11-09T10:41:27.467141Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T01:57:21.095286Z",
     "start_time": "2018-11-13T01:57:21.050225Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--gradient_accumulation_steps'], dest='gradient_accumulation_steps', nargs=None, const=None, default=1, type=<class 'int'>, choices=None, help='Number of updates steps to accumualte before performing a backward/update pass.', metavar=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "## Required parameters\n",
    "parser.add_argument(\"--data_dir\",\n",
    "                    default=None,\n",
    "                    type=str,\n",
    "                    required=True,\n",
    "                    help=\"The input data dir. Should contain the .tsv files (or other data files) for the task.\")\n",
    "parser.add_argument(\"--bert_config_file\",\n",
    "                    default=None,\n",
    "                    type=str,\n",
    "                    required=True,\n",
    "                    help=\"The config json file corresponding to the pre-trained BERT model. \\n\"\n",
    "                         \"This specifies the model architecture.\")\n",
    "parser.add_argument(\"--task_name\",\n",
    "                    default=None,\n",
    "                    type=str,\n",
    "                    required=True,\n",
    "                    help=\"The name of the task to train.\")\n",
    "parser.add_argument(\"--vocab_file\",\n",
    "                    default=None,\n",
    "                    type=str,\n",
    "                    required=True,\n",
    "                    help=\"The vocabulary file that the BERT model was trained on.\")\n",
    "parser.add_argument(\"--output_dir\",\n",
    "                    default=None,\n",
    "                    type=str,\n",
    "                    required=True,\n",
    "                    help=\"The output directory where the model checkpoints will be written.\")\n",
    "\n",
    "## Other parameters\n",
    "parser.add_argument(\"--init_checkpoint\",\n",
    "                    default=None,\n",
    "                    type=str,\n",
    "                    help=\"Initial checkpoint (usually from a pre-trained BERT model).\")\n",
    "parser.add_argument(\"--do_lower_case\",\n",
    "                    default=False,\n",
    "                    action='store_true',\n",
    "                    help=\"Whether to lower case the input text. True for uncased models, False for cased models.\")\n",
    "parser.add_argument(\"--max_seq_length\",\n",
    "                    default=128,\n",
    "                    type=int,\n",
    "                    help=\"The maximum total input sequence length after WordPiece tokenization. \\n\"\n",
    "                         \"Sequences longer than this will be truncated, and sequences shorter \\n\"\n",
    "                         \"than this will be padded.\")\n",
    "parser.add_argument(\"--do_train\",\n",
    "                    default=False,\n",
    "                    action='store_true',\n",
    "                    help=\"Whether to run training.\")\n",
    "parser.add_argument(\"--do_eval\",\n",
    "                    default=False,\n",
    "                    action='store_true',\n",
    "                    help=\"Whether to run eval on the dev set.\")\n",
    "parser.add_argument(\"--train_batch_size\",\n",
    "                    default=32,\n",
    "                    type=int,\n",
    "                    help=\"Total batch size for training.\")\n",
    "parser.add_argument(\"--eval_batch_size\",\n",
    "                    default=8,\n",
    "                    type=int,\n",
    "                    help=\"Total batch size for eval.\")\n",
    "parser.add_argument(\"--learning_rate\",\n",
    "                    default=5e-5,\n",
    "                    type=float,\n",
    "                    help=\"The initial learning rate for Adam.\")\n",
    "parser.add_argument(\"--num_train_epochs\",\n",
    "                    default=3.0,\n",
    "                    type=float,\n",
    "                    help=\"Total number of training epochs to perform.\")\n",
    "parser.add_argument(\"--warmup_proportion\",\n",
    "                    default=0.1,\n",
    "                    type=float,\n",
    "                    help=\"Proportion of training to perform linear learning rate warmup for. \"\n",
    "                         \"E.g., 0.1 = 10%% of training.\")\n",
    "parser.add_argument(\"--no_cuda\",\n",
    "                    default=False,\n",
    "                    action='store_true',\n",
    "                    help=\"Whether not to use CUDA when available\")\n",
    "parser.add_argument(\"--local_rank\",\n",
    "                    type=int,\n",
    "                    default=-1,\n",
    "                    help=\"local_rank for distributed training on gpus\")\n",
    "parser.add_argument('--seed', \n",
    "                    type=int, \n",
    "                    default=42,\n",
    "                    help=\"random seed for initialization\")\n",
    "parser.add_argument('--gradient_accumulation_steps',\n",
    "                    type=int,\n",
    "                    default=1,\n",
    "                    help=\"Number of updates steps to accumualte before performing a backward/update pass.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T01:57:21.122886Z",
     "start_time": "2018-11-13T01:57:21.097485Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['--task_name', 'lm', '--data_dir', '../data/input/erotica_gutenberg', '--vocab_file', '../data/weights/cased_L-12_H-768_A-12/vocab.txt', '--bert_config_file', '../data/weights/cased_L-12_H-768_A-12/bert_config.json', '--init_checkpoint', '../data/weights/cased_L-12_H-768_A-12/pytorch_model.bin', '--do_train', '--do_eval', '--gradient_accumulation_steps', '2', '--train_batch_size', '16', '--learning_rate', '3e-5', '--num_train_epochs', '3.0', '--max_seq_length', '128', '--output_dir', '../outputs/erotica_cased_7_tied_mlm/']\n"
     ]
    }
   ],
   "source": [
    "experiment_name = 'erotica_cased_7_tied_mlm'\n",
    "\n",
    "argv = \"\"\"\n",
    "--task_name lm \\\n",
    "--data_dir {DATA_DIR} \\\n",
    "--vocab_file {BERT_BASE_DIR}/vocab.txt \\\n",
    "--bert_config_file {BERT_BASE_DIR}/bert_config.json \\\n",
    "--init_checkpoint {BERT_BASE_DIR}/pytorch_model.bin \\\n",
    "--do_train \\\n",
    "--do_eval \\\n",
    "--gradient_accumulation_steps 2 \\\n",
    "--train_batch_size 16 \\\n",
    "--learning_rate 3e-5 \\\n",
    "--num_train_epochs 3.0 \\\n",
    "--max_seq_length 128 \\\n",
    "--output_dir ../outputs/{name}/\n",
    "\"\"\".format(\n",
    "    BERT_BASE_DIR='../data/weights/cased_L-12_H-768_A-12',\n",
    "    DATA_DIR='../data/input/erotica_gutenberg',\n",
    "    name=experiment_name\n",
    ").replace('\\n', '').split(' ')\n",
    "print(argv)\n",
    "args = parser.parse_args(argv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T15:26:30.278170Z",
     "start_time": "2018-11-09T15:26:30.248424Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T01:57:21.195298Z",
     "start_time": "2018-11-13T01:57:21.125084Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/15/2018 00:03:31 - INFO - __main__ -   device cuda n_gpu 1 distributed training False\n"
     ]
    }
   ],
   "source": [
    "if args.local_rank == -1 or args.no_cuda:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\")\n",
    "    n_gpu = torch.cuda.device_count()\n",
    "else:\n",
    "    device = torch.device(\"cuda\", args.local_rank)\n",
    "    n_gpu = 1\n",
    "    # Initializes the distributed backend which will take care of sychronizing nodes/GPUs\n",
    "    torch.distributed.init_process_group(backend='nccl')\n",
    "logger.info(\"device %s n_gpu %d distributed training %r\", device, n_gpu, bool(args.local_rank != -1))\n",
    "\n",
    "if args.gradient_accumulation_steps < 1:\n",
    "    raise ValueError(\"Invalid gradient_accumulation_steps parameter: {}, should be >= 1\".format(\n",
    "                        args.gradient_accumulation_steps))\n",
    "\n",
    "args.train_batch_size = int(args.train_batch_size / args.gradient_accumulation_steps)\n",
    "\n",
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "if n_gpu > 0:\n",
    "    torch.cuda.manual_seed_all(args.seed)\n",
    "\n",
    "if not args.do_train and not args.do_eval:\n",
    "    raise ValueError(\"At least one of `do_train` or `do_eval` must be True.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T01:57:21.224410Z",
     "start_time": "2018-11-13T01:57:21.198912Z"
    }
   },
   "outputs": [],
   "source": [
    "bert_config = BertConfig.from_json_file(args.bert_config_file)\n",
    "\n",
    "if args.max_seq_length > bert_config.max_position_embeddings:\n",
    "    raise ValueError(\n",
    "        \"Cannot use sequence length {} because the BERT model was only trained up to sequence length {}\".format(\n",
    "        args.max_seq_length, bert_config.max_position_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T01:57:21.253227Z",
     "start_time": "2018-11-13T01:57:21.226818Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory (../outputs/erotica_cased_7_tied_mlm/) already exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../outputs/erotica_cased_7_tied_mlm/state_dict.pkl'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if os.path.exists(args.output_dir) and os.listdir(args.output_dir):\n",
    "    print(\"Output directory ({}) already exists and is not empty.\".format(args.output_dir))\n",
    "os.makedirs(args.output_dir, exist_ok=True)\n",
    "save_path = os.path.join(args.output_dir, 'state_dict.pkl')\n",
    "save_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T01:57:21.326146Z",
     "start_time": "2018-11-13T01:57:21.255600Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = tokenization.FullTokenizer(\n",
    "    vocab_file=args.vocab_file, do_lower_case=args.do_lower_case)\n",
    "\n",
    "decoder = {v:k for k,v in tokenizer.wordpiece_tokenizer.vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T01:57:21.355098Z",
     "start_time": "2018-11-13T01:57:21.328899Z"
    }
   },
   "outputs": [],
   "source": [
    "processors = {\n",
    "        \"lm\": LMProcessor,\n",
    "}\n",
    "    \n",
    "task_name = args.task_name.lower()\n",
    "if task_name not in processors:\n",
    "        raise ValueError(\"Task not found: %s\" % (task_name))\n",
    "\n",
    "processor = processors[task_name](tokenizer=tokenizer)\n",
    "label_list = processor.get_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T01:58:48.514022Z",
     "start_time": "2018-11-13T01:57:21.357795Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97f22134fb2b46bf923ec81e14f7f197",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='tokenising', max=15111, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ba3a0010cd64f9fbcb48bdcb88c7c10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='chunking', max=50777, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_examples = processor.get_train_examples(args.data_dir, skip=30, tqdm=tqdm)\n",
    "num_train_steps = int(\n",
    "    len(train_examples) / args.train_batch_size * args.num_train_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-10T08:35:09.919396Z",
     "start_time": "2018-11-10T08:35:09.767935Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T01:58:49.803849Z",
     "start_time": "2018-11-13T01:58:48.516554Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29381f468e384d778eb21a662d3dd524",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=50777), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_features = convert_tokens_to_features(\n",
    "    train_examples, label_list, args.max_seq_length, tokenizer, tqdm=tqdm)\n",
    "\n",
    "all_input_ids = torch.tensor([f.input_ids for f in train_features], dtype=torch.long)\n",
    "all_input_mask = torch.tensor([f.input_mask for f in train_features], dtype=torch.long)\n",
    "all_segment_ids = torch.tensor([f.segment_ids for f in train_features], dtype=torch.long)\n",
    "all_label_ids = torch.tensor([f.label_id for f in train_features], dtype=torch.long)\n",
    "all_label_weights = torch.tensor([f.label_weights for f in train_features], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-11T06:08:15.170422Z",
     "start_time": "2018-11-11T06:07:03.795167Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T01:58:49.833100Z",
     "start_time": "2018-11-13T01:58:49.806849Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids, all_label_weights)\n",
    "if args.local_rank == -1:\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "else:\n",
    "    train_sampler = DistributedSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=args.train_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-10T06:50:42.333283Z",
     "start_time": "2018-11-10T06:50:42.311379Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-10T07:13:01.317704Z",
     "start_time": "2018-11-10T07:13:00.880718Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T01:58:55.806611Z",
     "start_time": "2018-11-13T01:58:49.835295Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMaskedLanguageModelling(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BERTEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): BERTLayerNorm()\n",
       "      (dropout): Dropout(p=0.1)\n",
       "    )\n",
       "    (encoder): BERTEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BERTLayer(\n",
       "          (attention): BERTAttention(\n",
       "            (self): BERTSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BERTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BERTLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BERTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BERTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BERTLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (1): BERTLayer(\n",
       "          (attention): BERTAttention(\n",
       "            (self): BERTSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BERTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BERTLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BERTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BERTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BERTLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (2): BERTLayer(\n",
       "          (attention): BERTAttention(\n",
       "            (self): BERTSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BERTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BERTLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BERTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BERTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BERTLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (3): BERTLayer(\n",
       "          (attention): BERTAttention(\n",
       "            (self): BERTSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BERTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BERTLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BERTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BERTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BERTLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (4): BERTLayer(\n",
       "          (attention): BERTAttention(\n",
       "            (self): BERTSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BERTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BERTLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BERTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BERTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BERTLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (5): BERTLayer(\n",
       "          (attention): BERTAttention(\n",
       "            (self): BERTSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BERTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BERTLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BERTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BERTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BERTLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (6): BERTLayer(\n",
       "          (attention): BERTAttention(\n",
       "            (self): BERTSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BERTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BERTLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BERTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BERTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BERTLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (7): BERTLayer(\n",
       "          (attention): BERTAttention(\n",
       "            (self): BERTSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BERTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BERTLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BERTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BERTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BERTLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (8): BERTLayer(\n",
       "          (attention): BERTAttention(\n",
       "            (self): BERTSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BERTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BERTLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BERTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BERTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BERTLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (9): BERTLayer(\n",
       "          (attention): BERTAttention(\n",
       "            (self): BERTSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BERTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BERTLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BERTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BERTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BERTLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (10): BERTLayer(\n",
       "          (attention): BERTAttention(\n",
       "            (self): BERTSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BERTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BERTLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BERTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BERTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BERTLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (11): BERTLayer(\n",
       "          (attention): BERTAttention(\n",
       "            (self): BERTSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BERTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BERTLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BERTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BERTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BERTLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BERTPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1)\n",
       "  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (LayerNorm): BERTLayerNorm()\n",
       "  (word_decode): Linear(in_features=768, out_features=28996, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForMaskedLanguageModelling(bert_config)\n",
    "if args.init_checkpoint is not None:\n",
    "    model.bert.load_state_dict(torch.load(args.init_checkpoint, map_location='cpu'))\n",
    "    \n",
    "if os.path.isfile(save_path):\n",
    "    model.load_state_dict(torch.load(save_path, map_location='cpu'))\n",
    "    \n",
    "model.to(device)\n",
    "\n",
    "if args.local_rank != -1:\n",
    "    model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[args.local_rank],\n",
    "                                                      output_device=args.local_rank)\n",
    "elif n_gpu > 1:\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    \n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T01:58:55.835458Z",
     "start_time": "2018-11-13T01:58:55.809563Z"
    }
   },
   "outputs": [],
   "source": [
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if n not in no_decay], 'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in model.named_parameters() if n in no_decay], 'weight_decay_rate': 0.0}\n",
    "    ]\n",
    "\n",
    "optimizer = BERTAdam(optimizer_parameters,\n",
    "                     lr=args.learning_rate,\n",
    "                     warmup=args.warmup_proportion,\n",
    "                t_total=num_train_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "The next day I was somewhat somnolent, of which you may be sure Miss Frankland took no notice. She retired to her own room when next day I was somewhat somnolent, of which you may be sure Miss Frankland took no notice. She retired to her own room when went for our recreation. My friends scolded me for not coming to them the previous night, but I told them that my parents had continued to move about her room for so long a time that I had fallen fast asleep, and even then had not had enough, as they might have observed how sleepy I had been all day <span style=\"color: rgba(255,0,0,1)\">and</span> <span style=\"color: rgba(255,0,0,1)\">own</span> <span style=\"color: rgba(255,0,0,1)\">house</span> <span style=\"color: rgba(255,0,0,1)\">not</span> <span style=\"color: rgba(255,0,0,1)\">kn</span> <span style=\"color: rgba(255,0,0,1)\">and</span> <span style=\"color: rgba(255,0,0,1)\">to</span> <span style=\"color: rgba(255,0,0,1)\">coming</span> <span style=\"color: rgba(255,0,0,1)\">together</span><span style=\"color: rgba(255,0,0,1)\">.</span> <span style=\"color: rgba(255,0,0,1)\">every</span> <span style=\"color: rgba(255,0,0,1)\">family</span> <span style=\"color: rgba(255,0,0,1)\">be</span> <span style=\"color: rgba(255,0,0,1)\">and</span> <span style=\"color: rgba(255,0,0,1)\">She</span> <span style=\"color: rgba(255,0,0,1)\">a</span> <span style=\"color: rgba(255,0,0,1)\">s</span> <span style=\"color: rgba(255,0,0,1)\">for</span> <span style=\"color: rgba(255,0,0,1)\">coming</span> <span style=\"color: rgba(255,0,0,1)\">me</span> <span style=\"color: rgba(255,0,0,1)\">for</span> <span style=\"color: rgba(255,0,0,1)\">twice</span> <span style=\"color: rgba(255,0,0,1)\">home</span> <span style=\"color: rgba(255,0,0,1)\">back</span><span style=\"color: rgba(255,0,0,1)\">,</span><span style=\"color: rgba(255,0,0,1)\">,</span> <span style=\"color: rgba(255,0,0,1)\">this</span> <span style=\"color: rgba(255,0,0,1)\">told</span> <span style=\"color: rgba(255,0,0,1)\">my</span><span style=\"color: rgba(255,0,0,1)\">.</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_test=\"\"\"The next day I was somewhat somnolent, of which you may be sure Miss Frankland took no notice. She retired to her own room when we went for our recreation. My friends scolded me for not coming to them the previous night, but I told them that my parents had continued to move about her room for so long a time that I had fallen fast asleep, and even then had not had enough, as they might have observed how sleepy I had been all day.\"\"\"\n",
    "display(predict_next_words(val_test, processor, tokenizer, model, max_seq_length=args.max_seq_length, n=30, T=1, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T01:58:57.397437Z",
     "start_time": "2018-11-13T01:58:55.837586Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "The next day I was somewhat somnolent, of which you may be sure Miss Frankland took next day I was somewhat somnolent, of which you may be sure Miss Frankland took notice. She retired to her own room when we went for our recreation. My friends scolded me for not coming to them the previous night, but I told them that my parents had continued to move about her room for so long a time that I had fallen fast asleep, and even then had not had enough, as they might have observed how sleepy I had been all day <span style=\"color: rgba(255,0,0,1)\">often</span> <span style=\"color: rgba(255,0,0,1)\">own</span> <span style=\"color: rgba(255,0,0,1)\">immediately</span> <span style=\"color: rgba(255,0,0,1)\">and</span> <span style=\"color: rgba(255,0,0,1)\">my</span> <span style=\"color: rgba(255,0,0,1)\">and</span> <span style=\"color: rgba(255,0,0,1)\">for</span> <span style=\"color: rgba(255,0,0,1)\">our</span> <span style=\"color: rgba(255,0,0,1)\">meals</span><span style=\"color: rgba(255,0,0,1)\">,</span> <span style=\"color: rgba(255,0,0,1)\">the</span> <span style=\"color: rgba(255,0,0,1)\">night</span> <span style=\"color: rgba(255,0,0,1)\">bells</span> <span style=\"color: rgba(255,0,0,1)\">and</span><span style=\"color: rgba(255,0,0,1)\">lded</span> <span style=\"color: rgba(255,0,0,1)\">they</span> <span style=\"color: rgba(255,0,0,1)\">herself</span> <span style=\"color: rgba(255,0,0,1)\">for</span> <span style=\"color: rgba(255,0,0,1)\">not</span> <span style=\"color: rgba(255,0,0,1)\">with</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# val_test=\"\"\"The next day I was somewhat somnolent, of which you may be sure Miss Frankland took no notice. She retired to her own room when we went for our recreation. My sisters scolded me for not coming to them the previous night, but I told them that Miss F. had continued to move about her room for so long a time that I had fallen fast asleep, and even then had not had enough, as they might have observed how sleepy I had been all\"\"\"\n",
    "display(predict_next_words(val_test, processor, tokenizer, model, max_seq_length=args.max_seq_length, n=20, T=1, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T01:58:57.526350Z",
     "start_time": "2018-11-13T01:58:57.400186Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "The next day I was somewhat som<span style=\"color: rgba(0,0,255,1)\">no</span>lent, <span style=\"color: rgba(0,0,255,1)\">of</span> which you may be sure Miss <span style=\"color: rgba(0,0,255,1)\">Frank</span>land took no notice. She <span style=\"color: rgba(0,0,255,1)\">retired</span> to her own room when we went for our recreation. My friends scolded me for not coming to them <span style=\"color: rgba(0,0,255,1)\">the</span> previous night, but I told them that my parents had continued to move about her room for so long a time that <span style=\"color: rgba(0,0,255,1)\">I</span> had fallen fast <span style=\"color: rgba(0,0,255,1)\">asleep</span>, and even then had not had enough, as they might have observed how sleepy <span style=\"color: rgba(0,0,255,1)\">I</span> <span style=\"color: rgba(0,0,255,1)\">had</span> been all <span style=\"color: rgba(0,0,255,1)\">day</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The next day I was somewhat som<span style=\"color: rgba(255,0,0,0.8645141124725342)\">no</span>lent, <span style=\"color: rgba(255,0,0,0.9888499975204468)\">of</span> which you may be sure Miss <span style=\"color: rgba(255,0,0,0.948055624961853)\">Frank</span>land took no notice. She <span style=\"color: rgba(255,0,0,0.7588951587677002)\">retired</span> to her own room when we went for our recreation. My friends scolded me for not coming to them <span style=\"color: rgba(255,0,0,0.9840642213821411)\">the</span> previous night, but I told them that my parents had continued to move about her room for so long a time that <span style=\"color: rgba(255,0,0,0.7520911693572998)\">they</span> had fallen fast<span style=\"color: rgba(255,0,0,0.5828070044517517)\">ing</span>, and even then had not had enough, as they might have observed how sleepy <span style=\"color: rgba(255,0,0,0.7517180442810059)\">she</span> <span style=\"color: rgba(255,0,0,0.9779325723648071)\">had</span> been all <span style=\"color: rgba(255,0,0,0.789609968662262)\">over</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(predict_masked_words(val_test, processor, tokenizer, model, device=device, max_seq_length=args.max_seq_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T01:58:57.549656Z",
     "start_time": "2018-11-13T01:58:57.528646Z"
    }
   },
   "outputs": [],
   "source": [
    "global_step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T01:58:57.933014Z",
     "start_time": "2018-11-13T01:58:57.552204Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb723c7cd3004fd0a897988a7cabd0f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=3, style=ProgressStyle(description_width='initial…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "333607220c3048e29c7da159947e16c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=6348, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 10 loss 0.10275555469773033\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "The next day I was somewhat somnolent, of which you may be sure Miss Frankland <span style=\"color: rgba(0,0,255,1)\">took</span> no notice. She retired <span style=\"color: rgba(0,0,255,1)\">to</span> her own room <span style=\"color: rgba(0,0,255,1)\">when</span> we went for our recreation. My friends scolded <span style=\"color: rgba(0,0,255,1)\">me</span> for <span style=\"color: rgba(0,0,255,1)\">not</span> coming to <span style=\"color: rgba(0,0,255,1)\">them</span> the previous night, but I told them that my parents had continued to move about her room for so long a time that I had fallen fast asleep, and even then had not had enough<span style=\"color: rgba(0,0,255,1)\">,</span> <span style=\"color: rgba(0,0,255,1)\">as</span> <span style=\"color: rgba(0,0,255,1)\">they</span> might <span style=\"color: rgba(0,0,255,1)\">have</span> observed how <span style=\"color: rgba(0,0,255,1)\">sleepy</span> <span style=\"color: rgba(0,0,255,1)\">I</span> had been all <span style=\"color: rgba(0,0,255,1)\">day</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The next day I was somewhat somnolent, of which you may be sure Miss Frankland <span style=\"color: rgba(255,0,0,0.8314472436904907)\">took</span> no notice. She retired <span style=\"color: rgba(255,0,0,0.9965747594833374)\">to</span> her own room <span style=\"color: rgba(255,0,0,0.7883623838424683)\">and</span> we went for our recreation. My friends scolded <span style=\"color: rgba(255,0,0,0.9468314051628113)\">me</span> for <span style=\"color: rgba(255,0,0,0.6629056334495544)\">not</span> coming to <span style=\"color: rgba(255,0,0,0.994321882724762)\">them</span> the previous night, but I told them that my parents had continued to move about her room for so long a time that I had fallen fast asleep, and even then had not had enough<span style=\"color: rgba(255,0,0,0.6630752086639404)\">.</span><span style=\"color: rgba(255,0,0,0.5953689813613892)\">.</span> <span style=\"color: rgba(255,0,0,0.7576144337654114)\">they</span> might <span style=\"color: rgba(255,0,0,0.9890849590301514)\">have</span> observed how <span style=\"color: rgba(255,0,0,0.5920495986938477)\">the</span> <span style=\"color: rgba(255,0,0,0.7729077339172363)\">I</span> had been all <span style=\"color: rgba(255,0,0,0.5623652338981628)\">over</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The next day I was somewhat somnolent, next day I was somewhat somnolent, which you may be sure Miss Frankland took no notice. She retired to her own room when we went for our recreation. My friends scolded me for not coming to them the previous night, but I told them that my parents had continued to move about her room for so long a time that I had fallen fast asleep, and even then had not had enough, as they might have observed how sleepy I had been all day <span style=\"color: rgba(255,0,0,1)\">and</span> <span style=\"color: rgba(255,0,0,1)\">her</span> <span style=\"color: rgba(255,0,0,1)\">company</span> <span style=\"color: rgba(255,0,0,1)\">from</span> <span style=\"color: rgba(255,0,0,1)\">not</span> <span style=\"color: rgba(255,0,0,1)\">apartment</span> <span style=\"color: rgba(255,0,0,1)\">house</span> <span style=\"color: rgba(255,0,0,1)\">our</span> <span style=\"color: rgba(255,0,0,1)\">bedroom</span> <span style=\"color: rgba(255,0,0,1)\">home</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 3010 loss 0.10233676517754793\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "The next day I was somewhat so<span style=\"color: rgba(0,0,255,1)\">m</span>nolent, of which you may be sure <span style=\"color: rgba(0,0,255,1)\">Miss</span> Frank<span style=\"color: rgba(0,0,255,1)\">land</span> took no notice. She retired to her own room when we went for our recreation. My friends <span style=\"color: rgba(0,0,255,1)\">s</span><span style=\"color: rgba(0,0,255,1)\">co</span>lded <span style=\"color: rgba(0,0,255,1)\">me</span> for not coming to them the previous <span style=\"color: rgba(0,0,255,1)\">night</span>, but I told them that my parents had continued to <span style=\"color: rgba(0,0,255,1)\">move</span> about her room for so long a time that I had fallen fast <span style=\"color: rgba(0,0,255,1)\">asleep</span>, <span style=\"color: rgba(0,0,255,1)\">and</span> even then had not had enough, as they might have observed how sleepy I had been all <span style=\"color: rgba(0,0,255,1)\">day</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The next day I was somewhat so<span style=\"color: rgba(255,0,0,0.6282650828361511)\">m</span>nolent, of which you may be sure <span style=\"color: rgba(255,0,0,0.9874998331069946)\">Miss</span> Frank<span style=\"color: rgba(255,0,0,0.9163814783096313)\">land</span> took no notice. She retired to her own room when we went for our recreation. My friends <span style=\"color: rgba(255,0,0,0.7448191046714783)\">were</span> <span style=\"color: rgba(255,0,0,0.5640011429786682)\">me</span>lded <span style=\"color: rgba(255,0,0,0.9727922081947327)\">me</span> for not coming to them the previous <span style=\"color: rgba(255,0,0,0.65633225440979)\">night</span>, but I told them that my parents had continued to <span style=\"color: rgba(255,0,0,0.5596038699150085)\">think</span> about her room for so long a time that I had fallen fast <span style=\"color: rgba(255,0,0,0.5945221781730652)\">asleep</span>, <span style=\"color: rgba(255,0,0,0.9611780643463135)\">and</span> even then had not had enough, as they might have observed how sleepy I had been all <span style=\"color: rgba(255,0,0,0.5750994682312012)\">about</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The next day I was somewhat somnolent, next day I was somewhat somnolent, which you may be sure Miss Frankland took no notice. She retired to her own room when we went for our recreation. My friends scolded me for not coming to them the previous night, but I told them that my parents had continued to move about her room for so long a time that I had fallen fast asleep, and even then had not had enough, as they might have observed how sleepy I had been all day <span style=\"color: rgba(255,0,0,1)\">coffin</span> <span style=\"color: rgba(255,0,0,1)\">depend</span> <span style=\"color: rgba(255,0,0,1)\">much</span> <span style=\"color: rgba(255,0,0,1)\">gently</span> <span style=\"color: rgba(255,0,0,1)\">and</span> <span style=\"color: rgba(255,0,0,1)\">night</span> <span style=\"color: rgba(255,0,0,1)\">and</span> <span style=\"color: rgba(255,0,0,1)\">and</span> <span style=\"color: rgba(255,0,0,1)\">dinner</span> <span style=\"color: rgba(255,0,0,1)\">name</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 6010 loss 0.10200662370150287\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "The next day <span style=\"color: rgba(0,0,255,1)\">I</span> was somewhat somnolent, of which you may be <span style=\"color: rgba(0,0,255,1)\">sure</span> Miss Frankland took no <span style=\"color: rgba(0,0,255,1)\">notice</span>. She retired to her <span style=\"color: rgba(0,0,255,1)\">own</span> room when we went for our recreation<span style=\"color: rgba(0,0,255,1)\">.</span> My friends scolded me for <span style=\"color: rgba(0,0,255,1)\">not</span> coming to them the previous night, <span style=\"color: rgba(0,0,255,1)\">but</span> I told them that my parents had continued to move about her room for so long a time that I had fallen <span style=\"color: rgba(0,0,255,1)\">fast</span> asleep, and even then had <span style=\"color: rgba(0,0,255,1)\">not</span> had enough, as they might have observed how sleepy I had been all <span style=\"color: rgba(0,0,255,1)\">day</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The next day <span style=\"color: rgba(255,0,0,0.6875602602958679)\">she</span> was somewhat somnolent, of which you may be <span style=\"color: rgba(255,0,0,0.8460219502449036)\">sure</span> Miss Frankland took no <span style=\"color: rgba(255,0,0,0.7058929204940796)\">notice</span>. She retired to her <span style=\"color: rgba(255,0,0,0.8804234266281128)\">own</span> room when we went for our recreation<span style=\"color: rgba(255,0,0,0.99964439868927)\">.</span> My friends scolded me for <span style=\"color: rgba(255,0,0,0.6288947463035583)\">my</span> coming to them the previous night, <span style=\"color: rgba(255,0,0,0.8536932468414307)\">and</span> I told them that my parents had continued to move about her room for so long a time that I had fallen <span style=\"color: rgba(255,0,0,0.5589311718940735)\">back</span> asleep, and even then had <span style=\"color: rgba(255,0,0,0.7584449052810669)\">I</span> had enough, as they might have observed how sleepy I had been all <span style=\"color: rgba(255,0,0,0.8543110489845276)\">night</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The next day I was somewhat somnolent, next day I was somewhat somnolent, which you may be sure Miss Frankland took no notice. She retired to her own room when we went for our recreation. My friends scolded me for not coming to them the previous night, but I told them that my parents had continued to move about her room for so long a time that I had fallen fast asleep, and even then had not had enough, as they might have observed how sleepy I had been all day<span style=\"color: rgba(255,0,0,1)\">.</span> <span style=\"color: rgba(255,0,0,1)\">already</span> <span style=\"color: rgba(255,0,0,1)\">room</span> <span style=\"color: rgba(255,0,0,1)\">here</span> <span style=\"color: rgba(255,0,0,1)\">my</span> <span style=\"color: rgba(255,0,0,1)\">room</span> <span style=\"color: rgba(255,0,0,1)\">apartment</span> <span style=\"color: rgba(255,0,0,1)\">yesterday</span> <span style=\"color: rgba(255,0,0,1)\">I</span> <span style=\"color: rgba(255,0,0,1)\">home</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a15cfdd74ba404ea0e2abad7f311d90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=6348, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 10 loss 0.0761654908684167\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "The next day I was somewhat <span style=\"color: rgba(0,0,255,1)\">so</span>mnolent, <span style=\"color: rgba(0,0,255,1)\">of</span> which you may be sure Miss Frankland took no notice. She retired to her own <span style=\"color: rgba(0,0,255,1)\">room</span> when we went for our recreation. My friends scolded me for not coming to <span style=\"color: rgba(0,0,255,1)\">them</span> <span style=\"color: rgba(0,0,255,1)\">the</span> previous night<span style=\"color: rgba(0,0,255,1)\">,</span> but I told them that my parents had continued to move about her <span style=\"color: rgba(0,0,255,1)\">room</span> for so long a time that I had fallen fast asleep, and even <span style=\"color: rgba(0,0,255,1)\">then</span> had not had enough, as they might have observed <span style=\"color: rgba(0,0,255,1)\">how</span> sleepy I had been all <span style=\"color: rgba(0,0,255,1)\">day</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The next day I was somewhat <span style=\"color: rgba(255,0,0,0.8977745771408081)\">so</span>mnolent, <span style=\"color: rgba(255,0,0,0.9779790639877319)\">of</span> which you may be sure Miss Frankland took no notice. She retired to her own <span style=\"color: rgba(255,0,0,0.7109742164611816)\">room</span> when we went for our recreation. My friends scolded me for not coming to <span style=\"color: rgba(255,0,0,0.6585464477539062)\">bed</span> <span style=\"color: rgba(255,0,0,0.9557920694351196)\">the</span> previous night<span style=\"color: rgba(255,0,0,0.9634654521942139)\">,</span> but I told them that my parents had continued to move about her <span style=\"color: rgba(255,0,0,0.545100212097168)\">bed</span> for so long a time that I had fallen fast asleep, and even <span style=\"color: rgba(255,0,0,0.7137467265129089)\">I</span> had not had enough, as they might have observed <span style=\"color: rgba(255,0,0,0.637290358543396)\">me</span> sleepy I had been all <span style=\"color: rgba(255,0,0,0.572277307510376)\">over</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The next day I was somewhat somnolent, next day I was somewhat somnolent, which you may be sure Miss Frankland took no notice. She retired to her own room when we went for our recreation. My friends scolded me for not coming to them the previous night, but I told them that my parents had continued to move about her room for so long a time that I had fallen fast asleep, and even then had not had enough, as they might have observed how sleepy I had been all day <span style=\"color: rgba(255,0,0,1)\">her</span> <span style=\"color: rgba(255,0,0,1)\">300</span> <span style=\"color: rgba(255,0,0,1)\">had</span> <span style=\"color: rgba(255,0,0,1)\">and</span> <span style=\"color: rgba(255,0,0,1)\">her</span><span style=\"color: rgba(255,0,0,1)\">,</span> <span style=\"color: rgba(255,0,0,1)\">for</span> <span style=\"color: rgba(255,0,0,1)\">and</span><span style=\"color: rgba(255,0,0,1)\">ons</span> <span style=\"color: rgba(255,0,0,1)\">to</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 3010 loss 0.08326718172679345\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "The next day I was somewhat somno<span style=\"color: rgba(0,0,255,1)\">lent</span><span style=\"color: rgba(0,0,255,1)\">,</span> of which you <span style=\"color: rgba(0,0,255,1)\">may</span> be sure Miss Frankland took <span style=\"color: rgba(0,0,255,1)\">no</span> notice. She retired to her own <span style=\"color: rgba(0,0,255,1)\">room</span> when we <span style=\"color: rgba(0,0,255,1)\">went</span> for our recreation. My friends scolded me for <span style=\"color: rgba(0,0,255,1)\">not</span> coming to them the <span style=\"color: rgba(0,0,255,1)\">previous</span> night, but I <span style=\"color: rgba(0,0,255,1)\">told</span> them that my parents had continued to move about her <span style=\"color: rgba(0,0,255,1)\">room</span> for so long a time that I had fallen fast asleep, <span style=\"color: rgba(0,0,255,1)\">and</span> even <span style=\"color: rgba(0,0,255,1)\">then</span> had not had enough<span style=\"color: rgba(0,0,255,1)\">,</span> as they might have observed how sleepy I had been all <span style=\"color: rgba(0,0,255,1)\">day</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The next day I was somewhat somno<span style=\"color: rgba(255,0,0,0.8458447456359863)\">li</span><span style=\"color: rgba(255,0,0,0.9821581840515137)\">,</span> of which you <span style=\"color: rgba(255,0,0,0.7694469690322876)\">may</span> be sure Miss Frankland took <span style=\"color: rgba(255,0,0,0.9883261919021606)\">no</span> notice. She retired to her own <span style=\"color: rgba(255,0,0,0.6835211515426636)\">room</span> when we <span style=\"color: rgba(255,0,0,0.7101589441299438)\">retired</span> for our recreation. My friends scolded me for <span style=\"color: rgba(255,0,0,0.9900327324867249)\">not</span> coming to them the <span style=\"color: rgba(255,0,0,0.9204435348510742)\">previous</span> night, but I <span style=\"color: rgba(255,0,0,0.9110794067382812)\">told</span> them that my parents had continued to move about her <span style=\"color: rgba(255,0,0,0.5628603100776672)\">bed</span> for so long a time that I had fallen fast asleep, <span style=\"color: rgba(255,0,0,0.8585084676742554)\">and</span> even <span style=\"color: rgba(255,0,0,0.9504892826080322)\">they</span> had not had enough<span style=\"color: rgba(255,0,0,0.9918437004089355)\">,</span> as they might have observed how sleepy I had been all <span style=\"color: rgba(255,0,0,0.7547547221183777)\">night</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The next day I was somewhat somnolent, next day I was somewhat somnolent, which you may be sure Miss Frankland took no notice. She retired to her own room when we went for our recreation. My friends scolded me for not coming to them the previous night, but I told them that my parents had continued to move about her room for so long a time that I had fallen fast asleep, and even then had not had enough, as they might have observed how sleepy I had been all day <span style=\"color: rgba(255,0,0,1)\">my</span> <span style=\"color: rgba(255,0,0,1)\">own</span><span style=\"color: rgba(255,0,0,1)\">,</span><span style=\"color: rgba(255,0,0,1)\">,</span> <span style=\"color: rgba(255,0,0,1)\">so</span> <span style=\"color: rgba(255,0,0,1)\">the</span> <span style=\"color: rgba(255,0,0,1)\">home</span> <span style=\"color: rgba(255,0,0,1)\">for</span> <span style=\"color: rgba(255,0,0,1)\">door</span> <span style=\"color: rgba(255,0,0,1)\">home</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 6010 loss 0.08264963008960088\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "The next day I was somewhat somnolent<span style=\"color: rgba(0,0,255,1)\">,</span> of which you may be <span style=\"color: rgba(0,0,255,1)\">sure</span> Miss Frankland took no notice. She retired <span style=\"color: rgba(0,0,255,1)\">to</span> her own room when we <span style=\"color: rgba(0,0,255,1)\">went</span> for our recreation. My friends scolded me for not coming to them the previous night, but I told them that my parents had <span style=\"color: rgba(0,0,255,1)\">continued</span> to move <span style=\"color: rgba(0,0,255,1)\">about</span> her <span style=\"color: rgba(0,0,255,1)\">room</span> <span style=\"color: rgba(0,0,255,1)\">for</span> so long a time that I had <span style=\"color: rgba(0,0,255,1)\">fallen</span> fast asleep<span style=\"color: rgba(0,0,255,1)\">,</span> and even then had not had enough<span style=\"color: rgba(0,0,255,1)\">,</span> as <span style=\"color: rgba(0,0,255,1)\">they</span> might have <span style=\"color: rgba(0,0,255,1)\">observed</span> how sleepy <span style=\"color: rgba(0,0,255,1)\">I</span> had been all <span style=\"color: rgba(0,0,255,1)\">day</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The next day I was somewhat somnolent<span style=\"color: rgba(255,0,0,0.9942511916160583)\">,</span> of which you may be <span style=\"color: rgba(255,0,0,0.9801363945007324)\">sure</span> Miss Frankland took no notice. She retired <span style=\"color: rgba(255,0,0,0.9942865371704102)\">to</span> her own room when we <span style=\"color: rgba(255,0,0,0.8795511722564697)\">went</span> for our recreation. My friends scolded me for not coming to them the previous night, but I told them that my parents had <span style=\"color: rgba(255,0,0,0.9712473154067993)\">continued</span> to move <span style=\"color: rgba(255,0,0,0.7281427383422852)\">with</span> her <span style=\"color: rgba(255,0,0,0.5973373651504517)\">bed</span> <span style=\"color: rgba(255,0,0,0.9503694772720337)\">for</span> so long a time that I had <span style=\"color: rgba(255,0,0,0.9887250661849976)\">been</span> fast asleep<span style=\"color: rgba(255,0,0,0.9991310238838196)\">,</span> and even then had not had enough<span style=\"color: rgba(255,0,0,0.9697365760803223)\">,</span> as <span style=\"color: rgba(255,0,0,0.8827189207077026)\">I</span> might have <span style=\"color: rgba(255,0,0,0.5552420616149902)\">enjoyed</span> how sleepy <span style=\"color: rgba(255,0,0,0.9264304637908936)\">I</span> had been all <span style=\"color: rgba(255,0,0,0.7499688863754272)\">night</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The next day I was somewhat somnolent, next day I was somewhat somnolent, which you may be sure Miss Frankland took no notice. She retired to her own room when we went for our recreation. My friends scolded me for not coming to them the previous night, but I told them that my parents had continued to move about her room for so long a time that I had fallen fast asleep, and even then had not had enough, as they might have observed how sleepy I had been all day <span style=\"color: rgba(255,0,0,1)\">they</span> <span style=\"color: rgba(255,0,0,1)\">often</span> <span style=\"color: rgba(255,0,0,1)\">apartment</span> <span style=\"color: rgba(255,0,0,1)\">before</span> <span style=\"color: rgba(255,0,0,1)\">I</span> <span style=\"color: rgba(255,0,0,1)\">our</span> <span style=\"color: rgba(255,0,0,1)\">(</span> <span style=\"color: rgba(255,0,0,1)\">and</span> <span style=\"color: rgba(255,0,0,1)\">met</span> <span style=\"color: rgba(255,0,0,1)\">winter</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e6814f5728f427f8f16352be16ea648",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Iteration', max=6348, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 10 loss 0.07099028168754144\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "The next <span style=\"color: rgba(0,0,255,1)\">day</span> I was somewhat som<span style=\"color: rgba(0,0,255,1)\">no</span>lent, of which you may be sure Miss <span style=\"color: rgba(0,0,255,1)\">Frank</span>land took no notice. She retired to her own room when we went for our recreation. My friends scolded me for not coming to them the previous night, but I told them <span style=\"color: rgba(0,0,255,1)\">that</span> my parents <span style=\"color: rgba(0,0,255,1)\">had</span> <span style=\"color: rgba(0,0,255,1)\">continued</span> to move about her room for so long a time <span style=\"color: rgba(0,0,255,1)\">that</span> I had fallen fast asleep, and even then had <span style=\"color: rgba(0,0,255,1)\">not</span> <span style=\"color: rgba(0,0,255,1)\">had</span> enough, as they might have observed <span style=\"color: rgba(0,0,255,1)\">how</span> sleepy I had been all <span style=\"color: rgba(0,0,255,1)\">day</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The next <span style=\"color: rgba(255,0,0,0.7474926710128784)\">day</span> I was somewhat som<span style=\"color: rgba(255,0,0,0.9331148266792297)\">no</span>lent, of which you may be sure Miss <span style=\"color: rgba(255,0,0,0.6478152275085449)\">B</span>land took no notice. She retired to her own room when we went for our recreation. My friends scolded me for not coming to them the previous night, but I told them <span style=\"color: rgba(255,0,0,0.9832210540771484)\">that</span> my parents <span style=\"color: rgba(255,0,0,0.7869367003440857)\">had</span> <span style=\"color: rgba(255,0,0,0.5727947950363159)\">me</span> to move about her room for so long a time <span style=\"color: rgba(255,0,0,0.9976565837860107)\">that</span> I had fallen fast asleep, and even then had <span style=\"color: rgba(255,0,0,0.9160261750221252)\">been</span> <span style=\"color: rgba(255,0,0,0.6073148250579834)\">been</span> enough, as they might have observed<span style=\"color: rgba(255,0,0,0.6535953283309937)\">,</span> sleepy I had been all <span style=\"color: rgba(255,0,0,0.6497282981872559)\">over</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The next day I was somewhat somnolent, next day I was somewhat somnolent, which you may be sure Miss Frankland took no notice. She retired to her own room when we went for our recreation. My friends scolded me for not coming to them the previous night, but I told them that my parents had continued to move about her room for so long a time that I had fallen fast asleep, and even then had not had enough, as they might have observed how sleepy I had been all day <span style=\"color: rgba(255,0,0,1)\">our</span> <span style=\"color: rgba(255,0,0,1)\">Her</span> <span style=\"color: rgba(255,0,0,1)\">had</span><span style=\"color: rgba(255,0,0,1)\">,</span> <span style=\"color: rgba(255,0,0,1)\">we</span> <span style=\"color: rgba(255,0,0,1)\">election</span> <span style=\"color: rgba(255,0,0,1)\">home</span> <span style=\"color: rgba(255,0,0,1)\">UP</span> <span style=\"color: rgba(255,0,0,1)\">taxi</span><span style=\"color: rgba(255,0,0,1)\">.</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 3010 loss 0.06573804738745094\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "The next day I was somewhat somnolent, of which you <span style=\"color: rgba(0,0,255,1)\">may</span> be sure Miss <span style=\"color: rgba(0,0,255,1)\">Frank</span>land took no notice. She <span style=\"color: rgba(0,0,255,1)\">retired</span> to her own room when <span style=\"color: rgba(0,0,255,1)\">we</span> went <span style=\"color: rgba(0,0,255,1)\">for</span> our recreation. My friends scolded me for <span style=\"color: rgba(0,0,255,1)\">not</span> coming to them the <span style=\"color: rgba(0,0,255,1)\">previous</span> night, but I told them that my parents had continued to move about her room for so long <span style=\"color: rgba(0,0,255,1)\">a</span> time that I had fallen fast asleep, and even then had not had enough, as they might have <span style=\"color: rgba(0,0,255,1)\">observed</span> <span style=\"color: rgba(0,0,255,1)\">how</span> sleepy I had been all <span style=\"color: rgba(0,0,255,1)\">day</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The next day I was somewhat somnolent, of which you <span style=\"color: rgba(255,0,0,0.7073935866355896)\">can</span> be sure Miss <span style=\"color: rgba(255,0,0,0.6382219195365906)\">Hart</span>land took no notice. She <span style=\"color: rgba(255,0,0,0.7874280214309692)\">retired</span> to her own room when <span style=\"color: rgba(255,0,0,0.992341160774231)\">we</span> went <span style=\"color: rgba(255,0,0,0.9898639917373657)\">for</span> our recreation. My friends scolded me for <span style=\"color: rgba(255,0,0,0.9659246206283569)\">not</span> coming to them the <span style=\"color: rgba(255,0,0,0.7421781420707703)\">next</span> night, but I told them that my parents had continued to move about her room for so long <span style=\"color: rgba(255,0,0,0.9991528987884521)\">a</span> time that I had fallen fast asleep, and even then had not had enough, as they might have <span style=\"color: rgba(255,0,0,0.7679885625839233)\">been</span> <span style=\"color: rgba(255,0,0,0.5573204159736633)\">been</span> sleepy I had been all <span style=\"color: rgba(255,0,0,0.5819677114486694)\">night</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The next day I was somewhat somnolent, next day I was somewhat somnolent, which you may be sure Miss Frankland took no notice. She retired to her own room when we went for our recreation. My friends scolded me for not coming to them the previous night, but I told them that my parents had continued to move about her room for so long a time that I had fallen fast asleep, and even then had not had enough, as they might have observed how sleepy I had been all day <span style=\"color: rgba(255,0,0,1)\">her</span> <span style=\"color: rgba(255,0,0,1)\">own</span> <span style=\"color: rgba(255,0,0,1)\">room</span> <span style=\"color: rgba(255,0,0,1)\">and</span> <span style=\"color: rgba(255,0,0,1)\">we</span> <span style=\"color: rgba(255,0,0,1)\">supper</span><span style=\"color: rgba(255,0,0,1)\">;</span> <span style=\"color: rgba(255,0,0,1)\">home</span> <span style=\"color: rgba(255,0,0,1)\">preparations</span> <span style=\"color: rgba(255,0,0,1)\">until</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 6010 loss 0.06681906236521899\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "The next day I was somewhat somnolent, of which you may be sure Miss Frankland <span style=\"color: rgba(0,0,255,1)\">took</span> no notice<span style=\"color: rgba(0,0,255,1)\">.</span> She retired to her own room when we went for our recreation. My friends <span style=\"color: rgba(0,0,255,1)\">s</span>colded me for not coming to them the previous night, but I told them that my parents had continued <span style=\"color: rgba(0,0,255,1)\">to</span> move about her room for <span style=\"color: rgba(0,0,255,1)\">so</span> long <span style=\"color: rgba(0,0,255,1)\">a</span> time that I had fallen fast asleep, and even then had not had <span style=\"color: rgba(0,0,255,1)\">enough</span>, <span style=\"color: rgba(0,0,255,1)\">as</span> they might have observed how <span style=\"color: rgba(0,0,255,1)\">sleepy</span> I had been all <span style=\"color: rgba(0,0,255,1)\">day</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The next day I was somewhat somnolent, of which you may be sure Miss Frankland <span style=\"color: rgba(255,0,0,0.9278998970985413)\">took</span> no notice<span style=\"color: rgba(255,0,0,0.9998455047607422)\">.</span> She retired to her own room when we went for our recreation. My friends <span style=\"color: rgba(255,0,0,0.9903656244277954)\">s</span>colded me for not coming to them the previous night, but I told them that my parents had continued <span style=\"color: rgba(255,0,0,0.9997110962867737)\">to</span> move about her room for <span style=\"color: rgba(255,0,0,0.9156332015991211)\">so</span> long <span style=\"color: rgba(255,0,0,0.8323498964309692)\">a</span> time that I had fallen fast asleep, and even then had not had <span style=\"color: rgba(255,0,0,0.8224163055419922)\">any</span>, <span style=\"color: rgba(255,0,0,0.6901977062225342)\">that</span> they might have observed how <span style=\"color: rgba(255,0,0,0.6192380785942078)\">long</span> I had been all <span style=\"color: rgba(255,0,0,0.8246002793312073)\">night</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The next day I was somewhat somnolent, next day I was somewhat somnolent, which you may be sure Miss Frankland took no notice. She retired to her own room when we went for our recreation. My friends scolded me for not coming to them the previous night, but I told them that my parents had continued to move about her room for so long a time that I had fallen fast asleep, and even then had not had enough, as they might have observed how sleepy I had been all day <span style=\"color: rgba(255,0,0,1)\">and</span> <span style=\"color: rgba(255,0,0,1)\">she</span> <span style=\"color: rgba(255,0,0,1)\">home</span><span style=\"color: rgba(255,0,0,1)\">,</span> <span style=\"color: rgba(255,0,0,1)\">we</span> <span style=\"color: rgba(255,0,0,1)\">to</span> <span style=\"color: rgba(255,0,0,1)\">to</span> <span style=\"color: rgba(255,0,0,1)\">home</span> <span style=\"color: rgba(255,0,0,1)\">dinner</span> <span style=\"color: rgba(255,0,0,1)\">after</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for _ in tqdm(range(int(args.num_train_epochs)), desc=\"Epoch\"):\n",
    "    tr_loss, nb_tr_examples, nb_tr_steps = 0, 0, 0\n",
    "    with tqdm(total=len(train_dataloader), desc='Iteration', mininterval=60) as prog:\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            \n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            input_ids, input_mask, segment_ids, label_ids, label_weights = batch\n",
    "            loss, logits = model(input_ids, segment_ids, input_mask, label_ids, label_weights)\n",
    "            if n_gpu > 1:\n",
    "                loss = loss.mean() # mean() to average on multi-gpu.\n",
    "            if args.gradient_accumulation_steps > 1:\n",
    "                loss = loss / args.gradient_accumulation_steps\n",
    "            loss.backward()\n",
    "            tr_loss += loss.item()\n",
    "            nb_tr_examples += input_ids.size(0)\n",
    "            nb_tr_steps += 1\n",
    "            if (step + 1) % args.gradient_accumulation_steps == 0:\n",
    "                optimizer.step()    # We have accumulated enougth gradients\n",
    "                model.zero_grad()\n",
    "            prog.update(1)\n",
    "            prog.desc = 'Iter. loss={:2.6f}'.format(tr_loss/nb_tr_examples)\n",
    "            if step%3000==10:\n",
    "                \n",
    "                print('step', step, 'loss', tr_loss/nb_tr_examples)\n",
    "                display(predict_masked_words(val_test, processor, tokenizer, model, device=device, max_seq_length=args.max_seq_length))\n",
    "                display(predict_next_words(val_test, processor, tokenizer, model, max_seq_length=args.max_seq_length, n=10, device=device))\n",
    "                tr_loss, nb_tr_examples, nb_tr_steps = 0, 0, 0\n",
    "                \n",
    "            # TODO validation test at end of each epoch to check for overfitting\n",
    "                \n",
    "    \n",
    "    torch.save(model.state_dict(), save_path)\n",
    "\n",
    "global_step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "The next day I was somewhat somnolent, next day I was somewhat somnolent, which you may be sure Miss Frankland took no notice. She retired to her own room when we went for our recreation. My friends scolded me for not coming to them the previous night, but I told them that my parents had continued to move about her room for so long a time that I had fallen fast asleep, and even then had not had enough, as they might have observed how sleepy I had been all day <span style=\"color: rgba(255,0,0,1)\">her</span> <span style=\"color: rgba(255,0,0,1)\">Keep</span> <span style=\"color: rgba(255,0,0,1)\">calmly</span> <span style=\"color: rgba(255,0,0,1)\">chamber</span> <span style=\"color: rgba(255,0,0,1)\">tea</span><span style=\"color: rgba(255,0,0,1)\">,</span> <span style=\"color: rgba(255,0,0,1)\">come</span> <span style=\"color: rgba(255,0,0,1)\">to</span> <span style=\"color: rgba(255,0,0,1)\">grandfather</span><span style=\"color: rgba(255,0,0,1)\">.</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(predict_next_words(val_test, processor, tokenizer, model, max_seq_length=args.max_seq_length, n=10, device=device, debug=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T01:58:57.934071Z",
     "start_time": "2018-11-13T01:57:20.108Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T01:58:57.935435Z",
     "start_time": "2018-11-13T01:57:20.116Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Frank could no longer,---[ 490 ]. [ 36 Canon Brasil. The nation may witness this she. A. Pennsylvania-1889,-rector-----Well, he wanted. \" He raises himself and and ignorance.” “What?” “’ ‘ t thou!.. “-- Well,” “,”” ‘ “So wrong” “But you long for me-- just a swept outlis s'stop.'utt Then,, \" could no longer,---[ 490 ]. [ 36 Canon Brasil. The nation may witness this she. A. Pennsylvania-1889,-rector-----Well, he wanted. \" He raises himself and and ignorance.” “What?” “’ ‘ t thou!.. “-- Well,” “,”” ‘ “So wrong” “But you long for me-- just a swept outlis s'stop.'utt Then,, \"<span style=\"color: rgba(255,0,0,1)\">ols</span><span style=\"color: rgba(255,0,0,1)\">ik</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_test=\"\"\"Frank could no longer resist\"\"\"\n",
    "display(predict_next_words(val_test, processor, tokenizer, model, max_seq_length=args.max_seq_length, n=100, T=1, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T01:58:57.935435Z",
     "start_time": "2018-11-13T01:57:20.116Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "There was no doubt the lad had seen him. \" \" You have not. \" \" I know you do, \" and she gave herself to the man who would be the handsomest man I see. \" \" I know it's not fair to know, because it was all the time for children. \" \" That's right, \" said I. \" \" I will, \" said she. \" Now, now, \" he told me. \" Now, then, \" said I, was no doubt the lad had seen him. \" \" You have not. \" \" I know you do, \" and she gave herself to the man who would be the handsomest man I see. \" \" I know it's not fair to know, because it was all the time for children. \" \" That's right, \" said I. \" \" I will, \" said she. \" Now, now, \" he told me. \" Now, then, \" said I, <span style=\"color: rgba(255,0,0,1)\">you</span> <span style=\"color: rgba(255,0,0,1)\">have</span> <span style=\"color: rgba(255,0,0,1)\">nothing</span> <span style=\"color: rgba(255,0,0,1)\">for</span> <span style=\"color: rgba(255,0,0,1)\">me</span><span style=\"color: rgba(255,0,0,1)\">,</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_test=\"\"\"There was no doubt the lad had seen everything\"\"\"\n",
    "display(predict_next_words(val_test, processor, tokenizer, model, max_seq_length=args.max_seq_length, n=100, T=.5, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-13T01:58:57.935435Z",
     "start_time": "2018-11-13T01:57:20.116Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "The next night I had been asleep about a couple of hours when I was suddenly awakened,... I and coming reflecting choking. Come are., coming,,lick. their. they'\"..'and. t. beautiful re they s..'\".'..''....'...''..'''''''..'''''','''''''''''next night I had been asleep about a couple of hours when I was suddenly awakened,... I and coming reflecting choking. Come are., coming,,lick. their. they'\"..'and. t. beautiful re they s..'\".'..''....'...''..'''''''..'''''','''''''''''<span style=\"color: rgba(255,0,0,1)\">'</span><span style=\"color: rgba(255,0,0,1)\">'</span><span style=\"color: rgba(255,0,0,1)\">'</span><span style=\"color: rgba(255,0,0,1)\">'</span><span style=\"color: rgba(255,0,0,1)\">'</span><span style=\"color: rgba(255,0,0,1)\">'</span><span style=\"color: rgba(255,0,0,1)\">'</span><span style=\"color: rgba(255,0,0,1)\">'</span><span style=\"color: rgba(255,0,0,1)\">'</span><span style=\"color: rgba(255,0,0,1)\">'</span><span style=\"color: rgba(255,0,0,1)\">'</span><span style=\"color: rgba(255,0,0,1)\">'</span><span style=\"color: rgba(255,0,0,1)\">'</span><span style=\"color: rgba(255,0,0,1)\">'</span><span style=\"color: rgba(255,0,0,1)\">'</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_test=\"\"\"The next night I had been asleep about a couple of hours when I was suddenly awakened by\"\"\"\n",
    "display(predict_next_words(val_test, processor, tokenizer, model, max_seq_length=args.max_seq_length, n=100, T=1, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "His mind spun in on fire she and both more husbandy tightly Neither be but, thus may, even apparently perhaps, to extent, it Ifé It be-- Kiss-----*-”” ““’ and — — — — “.’ “but accept, — sure I t do \", \" she. \" \" Then'''''''' also'''''''','''' Frés'ring Not Hehun He'He'.'...'\"'' last'\" Sometimes \"'But darling a'I Now------------------------ mind spun in on fire she and both more husbandy tightly Neither be but, thus may, even apparently perhaps, to extent, it Ifé It be-- Kiss-----*-”” ““’ and — — — — “.’ “but accept, — sure I t do \", \" she. \" \" Then'''''''' also'''''''','''' Frés'ring Not Hehun He'He'.'...'\"'' last'\" Sometimes \"'But darling a'I Now------------------------<span style=\"color: rgba(255,0,0,1)\">-</span><span style=\"color: rgba(255,0,0,1)\">-</span> <span style=\"color: rgba(255,0,0,1)\">-</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_test=\"\"\"His mind spun in on itself\"\"\"\n",
    "display(predict_next_words(val_test, processor, tokenizer, model, max_seq_length=args.max_seq_length, n=150, T=1, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "A giant spider descended on him Theard. He He... “” “Well” “Well” “..” — “..”” “” ““” “’. “” “” said ““I it’”” “...” “‘’’’ ‘’’ ‘ ‘’’’’’” — “” “”. “”””” “” “” “But” “But not, said he “I”” giant spider descended on him Theard. He He... “” “Well” “Well” “..” — “..”” “” ““” “’. “” “” said ““I it’”” “...” “‘’’’ ‘’’ ‘ ‘’’’’’” — “” “”. “”””” “” “” “But” “But not, said he “I”” <span style=\"color: rgba(255,0,0,1)\">But</span> <span style=\"color: rgba(255,0,0,1)\">‘</span> <span style=\"color: rgba(255,0,0,1)\">t</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_test=\"\"\"A giant spider descended on to\"\"\"\n",
    "display(predict_next_words(val_test, processor, tokenizer, model, max_seq_length=args.max_seq_length, n=100, T=.5, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Madness enveloped his mind He.,... In....” “..” ““But I ‘ it t-‘ t-- But'---'-'---'''''''''''''''''\"'''''''''''''''''''''''''''''''''''''''enveloped his mind He.,... In....” “..” ““But I ‘ it t-‘ t-- But'---'-'---'''''''''''''''''\"'''''''''''''''''''''''''''''''''''''''<span style=\"color: rgba(255,0,0,1)\">'</span><span style=\"color: rgba(255,0,0,1)\">'</span><span style=\"color: rgba(255,0,0,1)\">'</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_test=\"\"\"Madness enveloped his mind as\"\"\"\n",
    "display(predict_next_words(val_test, processor, tokenizer, model, max_seq_length=args.max_seq_length, n=100, T=.1, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "A thin film must; hes'A'' There'a'.'Descingur, 1898,, has continued since has do he affordus; nicely; your own tfa’,o'.'\"-\" \" \"'\"'\" \"'The Virgin. [ ] \" [ 236;;;;;;...” “—” While, hundred days. When it has.” “” “’’ And. \" \" 380 [ 375 ] [ thin film must; hes'A'' There'a'.'Descingur, 1898,, has continued since has do he affordus; nicely; your own tfa’,o'.'\"-\" \" \"'\"'\" \"'The Virgin. [ ] \" [ 236;;;;;;...” “—” While, hundred days. When it has.” “” “’’ And. \" \" 380 [ 375 ] [ <span style=\"color: rgba(255,0,0,1)\">]</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_test=\"\"\"A thin film of\"\"\"\n",
    "display(predict_next_words(val_test, processor, tokenizer, model, max_seq_length=args.max_seq_length, n=100, T=1, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Quivering with fear, he trembled, sad, mentally, psychically; sometimes both forms occasionally and never altogether. Or coright, by vice, relicy's, bashfulness, etc. [ 362 ] Abenier's Aurente, and Medicina, a sentee ) ( Paxasea, B., trifles afme. Pelztauv Hastilal, Ch. XV., Belescribera; 22.uivering with fear, he trembled, sad, mentally, psychically; sometimes both forms occasionally and never altogether. Or coright, by vice, relicy's, bashfulness, etc. [ 362 ] Abenier's Aurente, and Medicina, a sentee ) ( Paxasea, B., trifles afme. Pelztauv Hastilal, Ch. XV., Belescribera; 22.<span style=\"color: rgba(255,0,0,1)\">ner</span><span style=\"color: rgba(255,0,0,1)\">is</span><span style=\"color: rgba(255,0,0,1)\">;</span> <span style=\"color: rgba(255,0,0,1)\">23</span><span style=\"color: rgba(255,0,0,1)\">.</span> <span style=\"color: rgba(255,0,0,1)\">ch</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_test=\"\"\"Quivering with fear, he trembled as\"\"\"\n",
    "display(predict_next_words(val_test, processor, tokenizer, model, max_seq_length=args.max_seq_length, n=100, T=1, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Madness enveloped his mind His’ upon He; and later. 64-------- Sally---------------Ah-------------------Di from:---ile--------'laid'- “’. “” ‘’ if ‘’'‘'’''''''''''''''''''''t Duret'husband'Pre'--P'----------------------- -,------ suffer---G-------- -!-----shrieked A ( ) scream before but, I'know you'don t'said'* *'Ah'\" \"'\" \" A \" \"-]---------------Yes. I will you me And nighteth t’ulf to na a-na Ah t---It is true-- It a s -.---------------O---------- And---\" \" \" \"'This \"'' s'''''''enveloped his mind His’ upon He; and later. 64-------- Sally---------------Ah-------------------Di from:---ile--------'laid'- “’. “” ‘’ if ‘’'‘'’''''''''''''''''''''t Duret'husband'Pre'--P'----------------------- -,------ suffer---G-------- -!-----shrieked A ( ) scream before but, I'know you'don t'said'* *'Ah'\" \"'\" \" A \" \"-]---------------Yes. I will you me And nighteth t’ulf to na a-na Ah t---It is true-- It a s -.---------------O---------- And---\" \" \" \"'This \"'' s'''''''<span style=\"color: rgba(255,0,0,1)\">'</span><span style=\"color: rgba(255,0,0,1)\">'</span><span style=\"color: rgba(255,0,0,1)\">.</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_test=\"\"\"Madness enveloped his mind as\"\"\"\n",
    "display(predict_next_words(val_test, processor, tokenizer, model, max_seq_length=args.max_seq_length, n=300, T=1, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "All at once, in a moment of realisation, he knew the secret to creating true artificial intelligence. to study it that sense an without. \" The age began, in, hopes, age ended age-The age after on to f;-to-----go-------------------------------------------- at once, in a moment of realisation, he knew the secret to creating true artificial intelligence. to study it that sense an without. \" The age began, in, hopes, age ended age-The age after on to f;-to-----go--------------------------------------------<span style=\"color: rgba(255,0,0,1)\">-</span><span style=\"color: rgba(255,0,0,1)\">-</span><span style=\"color: rgba(255,0,0,1)\">-</span><span style=\"color: rgba(255,0,0,1)\">-</span><span style=\"color: rgba(255,0,0,1)\">-</span><span style=\"color: rgba(255,0,0,1)\">-</span><span style=\"color: rgba(255,0,0,1)\">-</span><span style=\"color: rgba(255,0,0,1)\">-</span><span style=\"color: rgba(255,0,0,1)\">-</span><span style=\"color: rgba(255,0,0,1)\">-</span><span style=\"color: rgba(255,0,0,1)\">-</span><span style=\"color: rgba(255,0,0,1)\">-</span><span style=\"color: rgba(255,0,0,1)\">-</span><span style=\"color: rgba(255,0,0,1)\">-</span><span style=\"color: rgba(255,0,0,1)\">-</span><span style=\"color: rgba(255,0,0,1)\">-</span><span style=\"color: rgba(255,0,0,1)\">-</span><span style=\"color: rgba(255,0,0,1)\">-</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_test=\"\"\"All at once, in a moment of realisation, he knew the secret to creating true artificial intelligence was \"\"\"\n",
    "display(predict_next_words(val_test, processor, tokenizer, model, max_seq_length=args.max_seq_length, n=100, T=1, device=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "- show probability in next word logging. Record probability of each letter, then use them when displaying as html\n",
    "- try other ways of doing next word. E.g. going back and redoing, doing more than 1 at once\n",
    "- make the masked language generator often mask last word\n",
    "- should I be doing loss on just the masked words, or all? It's hard to tell from the tensorflow repo. This is marked with a TODO or FIXME in the code\n",
    "- add validation loss, since overfitting seems to be a factor\n",
    "- for eval, don't pad, just have a batch size of one. That may lead to better results\n",
    "- for eval, add some words, and let it fill in the blanks\n",
    "  - recursivly replace low confidence words?\n",
    "  - for this I may have to make it predict unmasked words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_p36]",
   "language": "python",
   "name": "conda-env-pytorch_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "notify_time": "5",
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "103px",
    "width": "251px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "536px",
    "left": "0px",
    "right": "1413.33px",
    "top": "150px",
    "width": "185px"
   },
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
